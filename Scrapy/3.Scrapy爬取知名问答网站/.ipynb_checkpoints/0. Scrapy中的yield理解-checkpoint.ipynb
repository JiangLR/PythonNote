{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Scrapy中和yield生成器关系最紧密的就是parse()函数了,但是yield不仅只能在parse()中使用;但是只有在parse()中使用的yield才能把在整个Scrapy生命周期中生成的诸如item,item_loader传递给pipeline,然后让pipeline对item进行操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "class ZhihuSpider(scrapy.Spider):\n",
    "    name = 'zhihu'\n",
    "    allowed_domains = ['www.zhihu.com']\n",
    "    start_urls = ['http://www.zhihu.com/']\n",
    "\n",
    "    headers = {\n",
    "        \"HOST\": \"www.zhihu.com\",\n",
    "        \"Referer\": \"https://www.zhizhu.com\",\n",
    "        'User-Agent': \"Mozilla/5.0 (Windows NT 6.1; WOW64; rv:51.0) Gecko/20100101 Firefox/51.0\"\n",
    "    }\n",
    "\n",
    "    def parse(self, response):\n",
    "        # 具体操作...\n",
    "        pass\n",
    "\n",
    "    def start_requests(self):\n",
    "        return [scrapy.Request('https://www.zhihu.com/#signin', headers=self.headers, callback=self.login)]\n",
    "\n",
    "    def login(self, response):\n",
    "        response_text = response.text\n",
    "        match_obj = re.match('.*name=\"_xsrf\" value=\"(.*?)\"', response_text, re.DOTALL)\n",
    "        xsrf = ''\n",
    "        if match_obj:\n",
    "            xsrf = (match_obj.group(1))\n",
    "\n",
    "        if xsrf:\n",
    "            post_url = \"https://www.zhihu.com/login/phone_num\"\n",
    "            post_data = {\n",
    "                \"_xsrf\": xsrf,\n",
    "                \"phone_num\": \"18782902568\",\n",
    "                \"password\": \"admin123\"\n",
    "            }\n",
    "\n",
    "            return [scrapy.FormRequest(\n",
    "                url=post_url,\n",
    "                formdata=post_data,\n",
    "                headers=self.headers,\n",
    "                callback=self.check_login\n",
    "            )]\n",
    "\n",
    "    def check_login(self, response):\n",
    "        # 验证服务器的返回数据判断是否成功\n",
    "        text_json = json.loads(response.text)\n",
    "        if \"msg\" in text_json and text_json[\"msg\"] == \"登录成功\":\n",
    "            for url in self.start_urls:\n",
    "                yield scrapy.Request(url, dont_filter=True, headers=self.headers)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 先说下yield和return的关系,个人理解yield和return在Scrapy中的作用类似,yield返回的是一个生成器(个人理解为迭代器),而return返回的也是一个list\n",
    "    * yield scrapy.Request(url, dont_filter=True, headers=self.headers)\n",
    "    * return [scrapy.Request('https://www.zhihu.com/#signin', headers=self.headers, callback=self.login)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scrapy",
   "language": "python",
   "name": "scrapy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

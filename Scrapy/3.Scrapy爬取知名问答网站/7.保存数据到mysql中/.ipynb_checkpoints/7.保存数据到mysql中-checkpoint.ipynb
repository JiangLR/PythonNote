{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 首先明确一点,把爬取数据保存到数据库的操作是再pipeline.py在定义的\n",
    "2. 但是问题是针对入库操作对的PipeLine如果还是原来的写法,就要定制针对不同网站不同功能的入库PipeLine.比如针对爬取知乎的入库PipeLine;针对爬取B站的入库PipeLine.  \n",
    "    ##### 1. 问题的关键不在于MysqlTwistedPipline()里前面几个方法,前面几个方法基本上说都是写死的,因为这几个方法是针对配置来定义的.关键在于**do_insert()**.  \n",
    "    ##### 2. do_insert()只是针对'article'表进行的操作,无法针对其他表进行操作\n",
    "```\n",
    "class MysqlTwistedPipline(object):\n",
    "    def __init__(self, dbpool):\n",
    "        self.dbpool = dbpool\n",
    "\n",
    "    @classmethod\n",
    "    def from_settings(cls, settings):\n",
    "        dbparms = dict(\n",
    "            host=settings[\"MYSQL_HOST\"],\n",
    "            db=settings[\"MYSQL_DBNAME\"],\n",
    "            user=settings[\"MYSQL_USER\"],\n",
    "            passwd=settings[\"MYSQL_PASSWORD\"],\n",
    "            charset='utf8',\n",
    "            cursorclass=MySQLdb.cursors.DictCursor,\n",
    "            use_unicode=True,\n",
    "        )\n",
    "        dbpool = adbapi.ConnectionPool(\"MySQLdb\", **dbparms)\n",
    "\n",
    "        return cls(dbpool)\n",
    "\n",
    "    def process_item(self, item, spider):\n",
    "        # 使用twisted将mysql插入变成异步执行\n",
    "        query = self.dbpool.runInteraction(self.do_insert, item)\n",
    "        query.addErrback(self.handle_error, item, spider)  # 处理异常\n",
    "        return item\n",
    "\n",
    "    def handle_error(self, failure, item, spider):\n",
    "        # 处理异步插入的异常\n",
    "        print(failure)\n",
    "\n",
    "    def do_insert(self, cursor, item):\n",
    "        # 执行具体的插入\n",
    "        # 根据不同的item 构建不同的sql语句并插入到mysql中\n",
    "        insert_sql = \"\"\"\n",
    "                    insert into article(title, url, create_date, fav_nums, url_object_id)\n",
    "                    VALUES (%s, %s, %s, %s, %s)\n",
    "                \"\"\"\n",
    "        cursor.execute(insert_sql,\n",
    "                       (item[\"title\"], item[\"url\"], item[\"create_date\"], item[\"fav_nums\"], item[\"url_object_id\"]))\n",
    "```\n",
    "3. 解决办法:把类似的操作全部放入Item类中,针对本身Item定义数据库的操作方法,然后再PipLine中通过方法调用这些方法就能实现对特定Item操作数据库的实现\n",
    "```\n",
    "def do_insert(self, cursor, item):\n",
    "    #执行具体的插入\n",
    "    #根据不同的item 构建不同的sql语句并插入到mysql中\n",
    "    insert_sql, params = item.get_insert_sql()\n",
    "    cursor.execute(insert_sql, params)\n",
    "```\n",
    "##### do_insert()只进行整体逻辑上的操作(即一个PipeLine处理所有Item),具体的数值与数据库操作方法在对应的Item类中定义\n",
    "```\n",
    "class ZhihuAnswerItem(scrapy.Item):\n",
    "    #知乎的问题回答item\n",
    "    zhihu_id = scrapy.Field()\n",
    "    url = scrapy.Field()\n",
    "    question_id = scrapy.Field()\n",
    "    author_id = scrapy.Field()\n",
    "    content = scrapy.Field()\n",
    "    parise_num = scrapy.Field()\n",
    "    comments_num = scrapy.Field()\n",
    "    create_time = scrapy.Field()\n",
    "    update_time = scrapy.Field()\n",
    "    crawl_time = scrapy.Field()\n",
    "\n",
    "    def get_insert_sql(self):\n",
    "        #插入知乎question表的sql语句\n",
    "        insert_sql = \"\"\"\n",
    "            insert into zhihu_answer(zhihu_id, url, question_id, author_id, content, parise_num, comments_num,\n",
    "              create_time, update_time, crawl_time\n",
    "              ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "              ON DUPLICATE KEY UPDATE content=VALUES(content), comments_num=VALUES(comments_num), parise_num=VALUES(parise_num),\n",
    "              update_time=VALUES(update_time)\n",
    "        \"\"\"\n",
    "\n",
    "        create_time = datetime.datetime.fromtimestamp(self[\"create_time\"]).strftime(SQL_DATETIME_FORMAT)\n",
    "        update_time = datetime.datetime.fromtimestamp(self[\"update_time\"]).strftime(SQL_DATETIME_FORMAT)\n",
    "        params = (\n",
    "            self[\"zhihu_id\"], self[\"url\"], self[\"question_id\"],\n",
    "            self[\"author_id\"], self[\"content\"], self[\"parise_num\"],\n",
    "            self[\"comments_num\"], create_time, update_time,\n",
    "            self[\"crawl_time\"].strftime(SQL_DATETIME_FORMAT),\n",
    "        )\n",
    "\n",
    "        return insert_sql, params\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scrapy",
   "language": "python",
   "name": "scrapy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### URL去重原理\n",
    "1. Scrapy自带URL去重Middleware:'dupefilters.py':\n",
    "    * class BaseDupeFilter(object):默认过滤器  \n",
    "        |- def request_seen(self, request):  \n",
    "        * request_seen()在scheduler.py(调度器,调度request的分发)中的def enqueue_request(self, request)被使用\n",
    "        ```\n",
    "        def enqueue_request(self, request):\n",
    "            if not request.dont_filter and self.df.request_seen(request):\n",
    "                self.df.log(request, self.spider)\n",
    "                return False\n",
    "        ```\n",
    "        * dont_filter参数可以在Request中设置,在enqueue_request()被读取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### spider middleware\n",
    "1. 允许在Spider和Engine之间做一些处理,同样需要在setting.py里配置SPIDER_MIDDLEWARE\n",
    "2. SPIDER_MIDDLEWARE和DOWNLOADER_MIDDLEWARE都是被MiddlewareManager()类所控制的,而MiddlewareManager里定义了from_crawler(),所以说不管SPIDER_MIDDLEWARE还是DOWNLOADER_MIDDLEWARE,都可以去重写from_crawler(),比如可以在from_crawler()中定义某个信号量触发时实现的方法\n",
    "```\n",
    "class ArticlespiderSpiderMiddleware(object):\n",
    "    @classmethod\n",
    "    def from_crawler(cls, crawler):\n",
    "        # This method is used by Scrapy to create your spiders.\n",
    "        s = cls()\n",
    "        crawler.signals.connect(s.spider_opened, signal=signals.spider_opened)\n",
    "        return s\n",
    "        \n",
    "    def spider_opened(self, spider):\n",
    "        spider.logger.info('Spider opened: %s' % spider.name)\n",
    "```\n",
    "<img src='1.png' width=800px>\n",
    "3. 和DOWNLOADER_MIDDLEWARE一样,SPIDER_MIDDLEWARE有着默认的方法\n",
    "    * process_spider_input(response, spider)\n",
    "        * 该方法如果被重写,会在**⑥**被执行\n",
    "    * process_spider_output(response, result, spider)\n",
    "        * 该方法如果被重写,会在**⑦**被执行\n",
    "    * process_spider_exception(response, exception, spider)\n",
    "    * process_start_requests(start_requests, spider)\n",
    "        * 该方法如果被重写,会在**①**被执行\n",
    "    * from_crawler(cls, crawler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scrapy",
   "language": "python",
   "name": "scrapy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

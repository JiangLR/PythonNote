{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "class LagouSpider(CrawlSpider):\n",
    "    name = 'lagou'\n",
    "    allowed_domains = ['www.lagou.com']\n",
    "    start_urls = ['https://www.lagou.com']\n",
    "\n",
    "    rules = (\n",
    "        Rule(LinkExtractor(allow=(\"zhaopin/.*\",)), follow=True),\n",
    "        Rule(LinkExtractor(allow=(\"gongsi/j\\d+.html\",)), follow=True),\n",
    "        Rule(LinkExtractor(allow=r'jobs/\\d+.html'), callback='parse_job', follow=True),\n",
    "    )\n",
    "    \n",
    "    def parse_job(self, response):\n",
    "        pass\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "class Rule(object):\n",
    "    def __init__(self, link_extractor, callback=None, cb_kwargs=None, follow=None, process_links=None, process_request=identity):\n",
    "        pass\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 这里可以看到,Rule类的主要传递参数为\n",
    "    * link_extractor(链接提取器,提取那些需要爬取的网址)\n",
    "    * callback=None(回调函数)\n",
    "    * follow=None:是否跟进链接,若为True表示跟进('跟进'的意思是对该链接对应网页下的子链接进行同样的操作),如果Rule没有定义回调函数的话follow默认为True\n",
    "2. Rule的回调函数参数的定义和普通Spider定义方式相同\n",
    "```\n",
    "def parse_job(self, response):\n",
    "        #解析拉勾网的职位\n",
    "        item_loader = LagouJobItemLoader(item=LagouJobItem(), response=response)\n",
    "        item_loader.add_css(\"title\", \".job-name::attr(title)\")\n",
    "        item_loader.add_value(\"url_object_id\", get_md5(response.url))\n",
    "        item_loader.add_xpath(\"job_city\", \"//*[@class='job_request']/p/span[2]/text()\")\n",
    "        item_loader.add_css(\"job_advantage\", \".job-advantage p::text\")\n",
    "        item_loader.add_value(\"crawl_time\", datetime.now())\n",
    "\n",
    "        job_item = item_loader.load_item()\n",
    "\n",
    "        return job_item\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "class LxmlLinkExtractor(FilteringLinkExtractor):\n",
    "    def __init__(self, allow=(), deny=(), allow_domains=(), deny_domains=(), restrict_xpaths=(),\n",
    "                 tags=('a', 'area'), attrs=('href',), canonicalize=False,\n",
    "                 unique=True, process_value=None, deny_extensions=None, restrict_css=(),\n",
    "                 strip=True):\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 这里可以看到,LinkExtractor类的主要传递参数为\n",
    "    * allow=():是一个turple,指定允许爬取的网址,传递的是正则表达式(deny=()作用和allow()相反)\n",
    "    * allow_domains=():是一个turple,指定允许爬取的域名,传递的是正则表达式(deny_domains=()作用和allow_domains=()相反)\n",
    "    * restrict_xpaths=()/restrict_css=():使用xpath/css表达式，和allow共同作用过滤链接.\n",
    "        * rules = [Rule(LinkExtractor(allow = ('/job/list/.*',),restrict_xpaths=('//a[@number=\"numbers last\"]')), callback='parse_item')]# 提取下一页中的链接，跟进到下一页"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scrapy",
   "language": "python",
   "name": "scrapy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
